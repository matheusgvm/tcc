{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "dic_classes = {0: 'Abacaxi', 1: 'Acompanhar', 2: 'Acordar', 3: 'Acrescentar', 4: 'Alto'}\n",
    "\n",
    "# Carregar o modelo XGBoost previamente treinado\n",
    "model = xgb.Booster()\n",
    "model.load_model('xgboost_5_classes.model')\n",
    "# Definir o método da árvore para 'gpu_hist' para utilizar a GPU\n",
    "param = {'tree_method': 'gpu_hist'}\n",
    "# Atualizar os parâmetros do modelo\n",
    "model.set_param(param)\n",
    "\n",
    "# Inicializar o MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "# Inicializar a webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o frame\")\n",
    "        break\n",
    "\n",
    "    # Detectar as coordenadas dos gestos com o MediaPipe Holistic\n",
    "    results = holistic.process(frame)\n",
    "\n",
    "    gesture_coords = []\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        for landmark_id, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            gesture_coords.extend([landmark.x, landmark.y, landmark.z])\n",
    "    else:\n",
    "        gesture_coords.extend([math.nan] * 33 * 3)\n",
    "        \n",
    "    if results.left_hand_landmarks:\n",
    "        for landmark_id, landmark in enumerate(results.left_hand_landmarks.landmark):\n",
    "            gesture_coords.extend([landmark.x, landmark.y, landmark.z])\n",
    "    else:\n",
    "        gesture_coords.extend([math.nan] * 21 * 3) \n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        for landmark_id, landmark in enumerate(results.right_hand_landmarks.landmark):\n",
    "            gesture_coords.extend([landmark.x, landmark.y, landmark.z])\n",
    "    else:\n",
    "        gesture_coords.extend([math.nan] * 21 * 3) \n",
    "\n",
    "    gesture_coords = np.array(gesture_coords).reshape(1, -1)\n",
    "    prediction = model.predict(xgb.DMatrix(gesture_coords))[0]\n",
    "\n",
    "    # Mostrar o resultado da predição\n",
    "    if np.max(prediction) > 0.6:\n",
    "        prediction = dic_classes[np.argmax(prediction)]\n",
    "    else:\n",
    "        prediction = 'Nenhum'\n",
    "\n",
    "    cv2.putText(frame, f'Gesto: {prediction}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar o frame\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
